{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUeKVCYTbcyT"
      },
      "source": [
        "#### Copyright 2019, Autores do TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4ellrPx7tdxq"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JfLUlawto_D"
      },
      "source": [
        "# Classificação em dados desequilibrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwdpaTKJOoPu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver no TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar caderno</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mthoSGBAOoX-"
      },
      "source": [
        "Este tutorial demonstra como classificar um conjunto de dados altamente desequilibrado no qual o número de exemplos em uma classe supera em muito os exemplos em outra. Você trabalhará com o conjunto de dados de [detecção de fraude de cartão de crédito](https://www.kaggle.com/mlg-ulb/creditcardfraud) hospedado no Kaggle. O objetivo é detectar apenas 492 transações fraudulentas de um total de 284.807 transações. Você usará [Keras](../../guide/keras/overview.ipynb) para definir o modelo e [os pesos das classes](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model) para ajudar o modelo a aprender com os dados desequilibrados. .\n",
        "\n",
        "Este tutorial contém o código completo para:\n",
        "\n",
        "- Carregue um arquivo CSV usando o Pandas.\n",
        "- Crie conjuntos de treinamento, validação e teste.\n",
        "- Defina e treine um modelo usando Keras (incluindo a definição de pesos de classe).\n",
        "- Avalie o modelo usando várias métricas (incluindo precisão e recall).\n",
        "- Experimente técnicas comuns para lidar com dados desequilibrados, como:\n",
        "    - Ponderação da classe\n",
        "    - Sobreamostragem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRHmSyHxEIhN"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM7hDSNClfoK"
      },
      "outputs": [

      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8o1FHzD-_y_"
      },
      "outputs": [

      ],
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3iZVjziKHmX"
      },
      "source": [
        "## Processamento e exploração de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sA9WOcmzH2D"
      },
      "source": [
        "### Baixe o conjunto de dados de fraude de cartão de crédito Kaggle\n",
        "\n",
        "Pandas é uma biblioteca Python com muitos utilitários úteis para carregar e trabalhar com dados estruturados e pode ser usado para baixar CSVs em um dataframe.\n",
        "\n",
        "Note: This dataset has been collected and analysed during a research collaboration of Worldline and the [Machine Learning Group](http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available [here](https://www.researchgate.net/project/Fraud-detection-5) and the page of the [DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR_SnbMArXr7"
      },
      "outputs": [

      ],
      "source": [
        "file = tf.keras.utils\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fgdQgmwUFuj"
      },
      "outputs": [

      ],
      "source": [
        "raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKB_CVZFLpB"
      },
      "source": [
        "### Examine o desequilíbrio do rótulo da classe\n",
        "\n",
        "Vejamos o desequilíbrio do conjunto de dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCJFrtuY2iLF"
      },
      "outputs": [

      ],
      "source": [
        "neg, pos = np.bincount(raw_df['Class'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnLKFQDsCBUg"
      },
      "source": [
        "Isso mostra a pequena fração de amostras positivas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qox6ryyzwdr"
      },
      "source": [
        "### Limpe, divida e normalize os dados\n",
        "\n",
        "Os dados brutos têm alguns problemas. Primeiro, as colunas `Time` e `Amount` são muito variáveis para serem usadas diretamente. Elimine a coluna `Time` (já que não está claro o que significa) e pegue o log da coluna `Amount` para reduzir seu intervalo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef42jTuxEjnj"
      },
      "outputs": [

      ],
      "source": [
        "cleaned_df = raw_df.copy()\n",
        "\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop('Time')\n",
        "\n",
        "# The `Amount` column covers a huge range. Convert to log-space.\n",
        "eps=0.001 # 0 => 0.1¢\n",
        "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSNgdQFFFQ6u"
      },
      "source": [
        "Divida o conjunto de dados em conjuntos de treinamento, validação e teste. O conjunto de validação é usado durante o ajuste do modelo para avaliar a perda e quaisquer métricas, no entanto, o modelo não se ajusta a esses dados. O conjunto de teste não é usado durante a fase de treinamento e só é usado no final para avaliar quão bem o modelo generaliza para novos dados. Isso é especialmente importante com conjuntos de dados desequilibrados, onde o [overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) é uma preocupação significativa devido à falta de dados de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfxhKg7Yr1-b"
      },
      "outputs": [

      ],
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "bool_train_labels = train_labels != 0\n",
        "val_labels = np.array(val_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a_Z_kBmr7Oh"
      },
      "source": [
        "Normalize os recursos de entrada usando o sklearn StandardScaler. Isso definirá a média como 0 e o desvio padrão como 1.\n",
        "\n",
        "Nota: O `StandardScaler` só se encaixa usando `train_features` para ter certeza de que o modelo não está espiando os conjuntos de validação ou teste. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO-qEUmJ5JQg"
      },
      "outputs": [

      ],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "train_features = np.clip(train_features, -5, 5)\n",
        "val_features = np.clip(val_features, -5, 5)\n",
        "test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Validation labels shape:', val_labels.shape)\n",
        "print('Test labels shape:', test_labels.shape)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Validation features shape:', val_features.shape)\n",
        "print('Test features shape:', test_features.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF2nNfWKJ33w"
      },
      "source": [
        "Cuidado: Se você deseja implantar um modelo, é fundamental preservar os cálculos de pré-processamento. A maneira mais fácil de implementá-los como camadas e anexá-los ao seu modelo antes de exportar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ7m9nqDC3W6"
      },
      "source": [
        "### Observe a distribuição de dados\n",
        "\n",
        "Em seguida, compare as distribuições dos exemplos positivos e negativos em alguns recursos. Boas perguntas a se fazer neste momento são:\n",
        "\n",
        "- Essas distribuições fazem sentido?\n",
        "    - Sim. Você normalizou a entrada e estes estão principalmente concentrados na faixa `+/- 2` .\n",
        "- Você pode ver a diferença entre as distribuições?\n",
        "    - Sim, os exemplos positivos contêm uma taxa muito mais alta de valores extremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raK7hyjd_vf6"
      },
      "outputs": [

      ],
      "source": [
        "pos_df = pd.DataFrame(train_features[ bool_train_labels], columns = train_df.columns)\n",
        "neg_df = pd.DataFrame(train_features[~bool_train_labels], columns = train_df.columns)\n",
        "\n",
        "sns.jointplot(pos_df['V5'], pos_df['V6'],\n",
        "              kind='hex', xlim = (-5,5), ylim = (-5,5))\n",
        "plt.suptitle(\"Positive distribution\")\n",
        "\n",
        "sns.jointplot(neg_df['V5'], neg_df['V6'],\n",
        "              kind='hex', xlim = (-5,5), ylim = (-5,5))\n",
        "_ = plt.suptitle(\"Negative distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFK1u4JX16D8"
      },
      "source": [
        "## Defina o modelo e as métricas\n",
        "\n",
        "Definir uma função que cria uma rede neural simples com uma camada densly conectado escondida, um [abandono](https://developers.google.com/machine-learning/glossary/#dropout_regularization) camada para reduzir overfitting, e uma camada sigmóide saída que retorna a probabilidade de uma transação ser fraudulenta: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JQDzUqT3UYG"
      },
      "outputs": [

      ],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def make_model(metrics = METRICS, output_bias=None):\n",
        "  if output_bias is not None:\n",
        "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(\n",
        "          16, activation='relu',\n",
        "          input_shape=(train_features.shape[-1],)),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(1, activation='sigmoid',\n",
        "                         bias_initializer=output_bias),\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
        "      loss=keras.losses.BinaryCrossentropy(),\n",
        "      metrics=metrics)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU0GX6E6mieP"
      },
      "source": [
        "### Compreender métricas úteis\n",
        "\n",
        "Observe que existem algumas métricas definidas acima que podem ser calculadas pelo modelo e que serão úteis na avaliação do desempenho.\n",
        "\n",
        "- **Falsos** negativos e **falsos** positivos são amostras que foram classificadas **incorretamente**\n",
        "- **Verdadeiros** negativos e **verdadeiros** positivos são amostras que foram classificadas **corretamente**\n",
        "- **A precisão** é a porcentagem de exemplos classificados corretamente\n",
        "\n",
        "> $ \\ frac {\\ text {amostras verdadeiras}} {\\ text {amostras totais}} $\n",
        "\n",
        "- **A precisão** é a porcentagem de positivos **previstos** que foram classificados corretamente\n",
        "\n",
        "> $ \\ frac {\\ text {verdadeiros positivos}} {\\ text {verdadeiros positivos + falsos positivos}} $\n",
        "\n",
        "- **Lembre-se** é a porcentagem de positivos **reais** que foram classificados corretamente\n",
        "\n",
        "> $ \\ frac {\\ text {verdadeiros positivos}} {\\ text {verdadeiros positivos + falsos negativos}} $\n",
        "\n",
        "- **AUC** refere-se à área sob a curva de uma curva de característica de operação do receptor (ROC-AUC). Essa métrica é igual à probabilidade de que um classificador classifique uma amostra aleatória positiva mais alta do que uma amostra aleatória negativa.\n",
        "\n",
        "Observação: a precisão não é uma métrica útil para essa tarefa. Você pode obter 99,8% + de precisão nesta tarefa prevendo False o tempo todo.\n",
        "\n",
        "Consulte Mais informação:\n",
        "\n",
        "- [Verdadeiro x falso e positivo x negativo](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)\n",
        "- [Precisão](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
        "- [Precisão e recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)\n",
        "- [ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYdhSAoaF_TK"
      },
      "source": [
        "## Modelo de linha de base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDbltVPg2m2q"
      },
      "source": [
        "### Construir o modelo\n",
        "\n",
        "Agora crie e treine seu modelo usando a função que foi definida anteriormente. Observe que o modelo é ajustado usando um tamanho de lote maior do que o padrão de 2048, isso é importante para garantir que cada lote tenha uma chance decente de conter algumas amostras positivas. Se o tamanho do lote fosse muito pequeno, eles provavelmente não teriam transações fraudulentas com as quais aprender.\n",
        "\n",
        "Observação: este modelo não lidará bem com o desequilíbrio de classe. Você irá aprimorá-lo posteriormente neste tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouUkwPcGQsy3"
      },
      "outputs": [

      ],
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xlR_dekzw7C"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx7ND3_SqckO"
      },
      "source": [
        "Teste o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LopSd-yQqO3a"
      },
      "outputs": [

      ],
      "source": [
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKIgWqHms_03"
      },
      "source": [
        "### Opcional: defina a polarização inicial correta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk_3Ry6EoYDq"
      },
      "source": [
        "Essas suposições iniciais não são boas. Você sabe que o conjunto de dados está desequilibrado. Defina o viés da camada de saída para refletir isso (consulte: [Uma receita para o treinamento de redes neurais: \"init well\"](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines) ). Isso pode ajudar na convergência inicial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdbfWDuVpo6k"
      },
      "source": [
        "Com a inicialização de polarização padrão, a perda deve ser de cerca de `math.log(2) = 0.69314` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-oPqh3SoGXk"
      },
      "outputs": [

      ],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE-JRzfKqfhB"
      },
      "source": [
        "A polarização correta a ser definida pode ser derivada de:\n",
        "\n",
        "$$ p_0 = pos / (pos + neg) = 1 / (1 + e ^ {- b_0}) $$ $$ b_0 = -log_e (1 / p_0 - 1) $$ $$ b_0 = log_e (pos / neg ) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5KWPSjjstUS"
      },
      "outputs": [

      ],
      "source": [
        "initial_bias = np.log([pos/neg])\n",
        "initial_bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1juXI9yY1KD"
      },
      "source": [
        "Defina isso como o viés inicial e o modelo dará suposições iniciais muito mais razoáveis.\n",
        "\n",
        "Deve estar próximo a: `pos/total = 0.0018`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50oyu1uss0i-"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model(output_bias = initial_bias)\n",
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xqFYb2KqRHQ"
      },
      "source": [
        "Com esta inicialização, a perda inicial deve ser de aproximadamente:\n",
        "\n",
        "$$ - p_0log (p_0) - (1-p_0) log (1-p_0) = 0,01317 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVDqCWXDqHSc"
      },
      "outputs": [

      ],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDC8hvNr9yw"
      },
      "source": [
        "Essa perda inicial é cerca de 50 vezes menor do que teria ocorrido com a inicialização ingênua.\n",
        "\n",
        "Dessa forma, o modelo não precisa passar as primeiras épocas apenas aprendendo que exemplos positivos são improváveis. Isso também facilita a leitura dos gráficos de perda durante o treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJj9ixKVBMT"
      },
      "source": [
        "### Verifique os pesos iniciais\n",
        "\n",
        "Para tornar as várias execuções de treinamento mais comparáveis, mantenha os pesos deste modelo inicial em um arquivo de checkpoint e carregue-os em cada modelo antes do treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tSUm4yAVIif"
      },
      "outputs": [

      ],
      "source": [
        "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVXiLyqyZ8AX"
      },
      "source": [
        "### Confirme se a correção de viés ajuda\n",
        "\n",
        "Antes de prosseguir, confirme rapidamente se a inicialização de polarização cuidadosa realmente ajudou.\n",
        "\n",
        "Treine o modelo por 20 épocas, com e sem essa inicialização cuidadosa, e compare as perdas: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm4-4K5RZ63Q"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "model.layers[-1].bias.assign([0.0])\n",
        "zero_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8DsLXHQaSql"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "careful_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3XsMBjhauFV"
      },
      "outputs": [

      ],
      "source": [
        "def plot_loss(history, label, n):\n",
        "  # Use a log scale to show the wide range of values.\n",
        "  plt.semilogy(history.epoch,  history.history['loss'],\n",
        "               color=colors[n], label='Train '+label)\n",
        "  plt.semilogy(history.epoch,  history.history['val_loss'],\n",
        "          color=colors[n], label='Val '+label,\n",
        "          linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  \n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxFaskm7beC7"
      },
      "outputs": [

      ],
      "source": [
        "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
        "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKMioV0ddG3R"
      },
      "source": [
        "A figura acima deixa claro: Em termos de perda de validação, neste problema, esta inicialização cuidadosa dá uma vantagem clara. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsA_7SEntRaV"
      },
      "source": [
        "### Treine o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKAc8NCDnoR"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "baseline_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSaDBYU9xtP6"
      },
      "source": [
        "### Verifique o histórico de treinamento\n",
        "\n",
        "Nesta seção, você produzirá gráficos da precisão e perda do seu modelo no conjunto de treinamento e validação. Eles são úteis para verificar se há overfitting, sobre o qual você pode aprender mais neste [tutorial](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit) .\n",
        "\n",
        "Além disso, você pode produzir esses gráficos para qualquer uma das métricas criadas acima. Os falsos negativos são incluídos como exemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTSkhT1jyGu6"
      },
      "outputs": [

      ],
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6LReDsqlZlk"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(baseline_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCa4iWo6WDKR"
      },
      "source": [
        "Observação: que a curva de validação geralmente tem um desempenho melhor do que a curva de treinamento. Isso é causado principalmente pelo fato de que a camada de dropout não está ativa ao avaliar o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJC1booryouo"
      },
      "source": [
        "### Avalie as métricas\n",
        "\n",
        "Você pode usar uma [matriz de confusão](https://developers.google.com/machine-learning/glossary/#confusion_matrix) para resumir os rótulos reais e previstos, em que o eixo X é o rótulo previsto e o eixo Y é o rótulo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNS796IJKrev"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVWBGfADwbWI"
      },
      "outputs": [

      ],
      "source": [
        "def plot_cm(labels, predictions, p=0.5):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "  plt.ylabel('Actual label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOTjD5Z5Wp1U"
      },
      "source": [
        "Avalie seu modelo no conjunto de dados de teste e exiba os resultados para as métricas que você criou acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poh_hZngt2_9"
      },
      "outputs": [

      ],
      "source": [
        "baseline_results = model.evaluate(test_features, test_labels,\n",
        "                                  batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyZtSr1v6L4t"
      },
      "source": [
        "Se o modelo tivesse previsto tudo perfeitamente, esta seria uma [matriz diagonal](https://en.wikipedia.org/wiki/Diagonal_matrix) onde os valores fora da diagonal principal, indicando previsões incorretas, seriam zero. Nesse caso, a matriz mostra que você tem relativamente poucos falsos positivos, o que significa que havia relativamente poucas transações legítimas que foram sinalizadas incorretamente. No entanto, você provavelmente desejaria ter ainda menos falsos negativos, apesar do custo de aumentar o número de falsos positivos. Essa troca pode ser preferível porque os falsos negativos permitiriam a realização de transações fraudulentas, ao passo que os falsos positivos podem fazer com que um e-mail seja enviado a um cliente solicitando a verificação da atividade do cartão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-QpQsip_F2Q"
      },
      "source": [
        "### Trace o ROC\n",
        "\n",
        "Agora plote o [ROC](https://developers.google.com/machine-learning/glossary#ROC) . Este gráfico é útil porque mostra, de relance, a faixa de desempenho que o modelo pode atingir apenas ajustando o limite de saída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhaxsLSvANF9"
      },
      "outputs": [

      ],
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,20])\n",
        "  plt.ylim([80,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfHHspttKJE0"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdsFyp64DhY"
      },
      "source": [
        "Parece que a precisão é relativamente alta, mas o recall e a área sob a curva ROC (AUC) não são tão altas quanto você gostaria. Os classificadores geralmente enfrentam desafios ao tentar maximizar a precisão e a recuperação, o que é especialmente verdadeiro quando se trabalha com conjuntos de dados desequilibrados. É importante considerar os custos dos diferentes tipos de erros no contexto do problema com o qual você se preocupa. Neste exemplo, um falso negativo (uma transação fraudulenta é perdida) pode ter um custo financeiro, enquanto um falso positivo (uma transação é sinalizada incorretamente como fraudulenta) pode diminuir a felicidade do usuário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cveQoiMyGQCo"
      },
      "source": [
        "## Pesos de classe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePGp6GUE1WfH"
      },
      "source": [
        "### Calcular pesos de classe\n",
        "\n",
        "O objetivo é identificar transações fraudulentas, mas você não tem muitas dessas amostras positivas para trabalhar, então você gostaria que o classificador pesasse muito os poucos exemplos que estão disponíveis. Você pode fazer isso passando pesos Keras para cada classe por meio de um parâmetro. Isso fará com que o modelo \"preste mais atenção\" aos exemplos de uma classe sub-representada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjGWErngGny7"
      },
      "outputs": [

      ],
      "source": [
        "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
        "# The sum of the weights of all examples stays the same.\n",
        "weight_for_0 = (1 / neg)*(total)/2.0 \n",
        "weight_for_1 = (1 / pos)*(total)/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk1OOE2ZSHzy"
      },
      "source": [
        "### Treine um modelo com pesos de classe\n",
        "\n",
        "Agora tente treinar novamente e avaliar o modelo com pesos de classe para ver como isso afeta as previsões.\n",
        "\n",
        "Nota: Usar `class_weights` muda o intervalo da perda. Isso pode afetar a estabilidade do treinamento dependendo do otimizador. Otimizadores cujo tamanho do passo depende da magnitude do gradiente, como `optimizers.SGD` , podem falhar. O otimizador usado aqui, `optimizers.Adam` , não é afetado pela mudança de escala. Observe também que, devido à ponderação, as perdas totais não são comparáveis entre os dois modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ589fn8ST3x"
      },
      "outputs": [

      ],
      "source": [
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0ynYRO0G3Lx"
      },
      "source": [
        "### Verifique o histórico de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBe9FMO5ucTC"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(weighted_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy6WClTZIwQ"
      },
      "source": [
        "### Avalie as métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nifqscPGw-5w"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owKL2vdMBJr6"
      },
      "outputs": [

      ],
      "source": [
        "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
        "                                           batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_weighted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTh1rtDn8r4-"
      },
      "source": [
        "Aqui você pode ver que, com pesos de classe, a exatidão e a precisão são menores porque há mais falsos positivos, mas, inversamente, a recuperação e a AUC são maiores porque o modelo também encontrou mais positivos verdadeiros. Apesar de ter menor precisão, este modelo tem maior recall (e identifica mais transações fraudulentas). Obviamente, há um custo para os dois tipos de erro (você também não gostaria de incomodar os usuários sinalizando muitas transações legítimas como fraudulentas). Considere cuidadosamente as compensações entre esses diferentes tipos de erros para seu aplicativo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXDAwyr0HYdX"
      },
      "source": [
        "### Trace o ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hzScIVZS1Xm"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
        "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
        "\n",
        "\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ysRtr6xHnXP"
      },
      "source": [
        "## Sobreamostragem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18VUHNc-UF5w"
      },
      "source": [
        "### Superamostrar a classe minoritária\n",
        "\n",
        "Uma abordagem relacionada seria reamostrar o conjunto de dados sobreamostrando a classe minoritária."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHirNp6u7OWp"
      },
      "outputs": [

      ],
      "source": [
        "pos_features = train_features[bool_train_labels]\n",
        "neg_features = train_features[~bool_train_labels]\n",
        "\n",
        "pos_labels = train_labels[bool_train_labels]\n",
        "neg_labels = train_labels[~bool_train_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBVbX7P7QrL"
      },
      "source": [
        "#### Usando NumPy\n",
        "\n",
        "Você pode equilibrar o conjunto de dados manualmente, escolhendo o número certo de índices aleatórios dos exemplos positivos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUzGjSkwqT88"
      },
      "outputs": [

      ],
      "source": [
        "ids = np.arange(len(pos_features))\n",
        "choices = np.random.choice(ids, len(neg_features))\n",
        "\n",
        "res_pos_features = pos_features[choices]\n",
        "res_pos_labels = pos_labels[choices]\n",
        "\n",
        "res_pos_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ie_FFet6cep"
      },
      "outputs": [

      ],
      "source": [
        "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
        "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
        "\n",
        "order = np.arange(len(resampled_labels))\n",
        "np.random.shuffle(order)\n",
        "resampled_features = resampled_features[order]\n",
        "resampled_labels = resampled_labels[order]\n",
        "\n",
        "resampled_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYfJe2Kc-FAz"
      },
      "source": [
        "#### Usando `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyixaST8v5P"
      },
      "source": [
        "Se você estiver usando `tf.data` a maneira mais fácil de produzir exemplos equilibrados é começar com um conjunto de dados `positive` e um `negative` e mesclá-los. Veja [o guia tf.data](../../guide/data.ipynb) para mais exemplos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF4OZ-rI6xb6"
      },
      "outputs": [

      ],
      "source": [
        "BUFFER_SIZE = 100000\n",
        "\n",
        "def make_ds(features, labels):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
        "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
        "  return ds\n",
        "\n",
        "pos_ds = make_ds(pos_features, pos_labels)\n",
        "neg_ds = make_ds(neg_features, neg_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNQUx-OA-oJc"
      },
      "source": [
        "Cada conjunto de dados fornece pares `(feature, label)` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llXc9rNH7Fbz"
      },
      "outputs": [

      ],
      "source": [
        "for features, label in pos_ds.take(1):\n",
        "  print(\"Features:\\n\", features.numpy())\n",
        "  print()\n",
        "  print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLEfjZO0-vbN"
      },
      "source": [
        "Junte os dois usando `experimental.sample_from_datasets` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7w9UQPT9wzE"
      },
      "outputs": [

      ],
      "source": [
        "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
        "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWXARdTdAuQK"
      },
      "outputs": [

      ],
      "source": [
        "for features, label in resampled_ds.take(1):\n",
        "  print(label.numpy().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irgqf3YxAyN0"
      },
      "source": [
        "Para usar este conjunto de dados, você precisará do número de etapas por época.\n",
        "\n",
        "A definição de \"época\", neste caso, é menos clara. Digamos que seja o número de lotes necessários para ver cada exemplo negativo uma vez:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH-7K46AAxpq"
      },
      "outputs": [

      ],
      "source": [
        "resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
        "resampled_steps_per_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ1BvEpcBVHP"
      },
      "source": [
        "### Treine nos dados sobreamostrados\n",
        "\n",
        "Agora tente treinar o modelo com o conjunto de dados reamostrado em vez de usar pesos de classe para ver como esses métodos se comparam.\n",
        "\n",
        "Nota: Como os dados foram balanceados replicando os exemplos positivos, o tamanho total do conjunto de dados é maior e cada época executa mais etapas de treinamento. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soRQ89JYqd6b"
      },
      "outputs": [

      ],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=resampled_steps_per_epoch,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avALvzUp3T_c"
      },
      "source": [
        "Se o processo de treinamento considerasse todo o conjunto de dados em cada atualização de gradiente, essa sobreamostragem seria basicamente idêntica à ponderação da classe.\n",
        "\n",
        "Mas ao treinar o modelo em lote, como você fez aqui, os dados sobreamostrados fornecem um sinal de gradiente mais suave: em vez de cada exemplo positivo sendo mostrado em um lote com um grande peso, eles são mostrados em muitos lotes diferentes a cada vez com um peso pequeno.\n",
        "\n",
        "Este sinal de gradiente mais suave torna mais fácil treinar o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHZ0HV76VC5"
      },
      "source": [
        "### Verifique o histórico de treinamento\n",
        "\n",
        "Observe que as distribuições de métricas serão diferentes aqui, porque os dados de treinamento têm uma distribuição totalmente diferente dos dados de validação e teste. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoUGfr1vuivl"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(resampled_history )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PuH3A2vnwrh"
      },
      "source": [
        "### Re-treinar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLxRL8eoDE5"
      },
      "source": [
        "Como o treinamento é mais fácil com os dados balanceados, o procedimento de treinamento acima pode se ajustar rapidamente.\n",
        "\n",
        "So break up the epochs to give the `callbacks.EarlyStopping` finer control over when to stop training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_yn9I26qAHU"
      },
      "outputs": [

      ],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    # These are not real epochs\n",
        "    steps_per_epoch = 20,\n",
        "    epochs=10*EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuJYKv0gpBK1"
      },
      "source": [
        "### Verifique novamente o histórico de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMycrpJwn39w"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(resampled_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUuE5HOWZiwP"
      },
      "source": [
        "### Avalie as métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0fmHSgXxFdW"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_resampled = resampled_model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_resampled = resampled_model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO0mMOYUDWFk"
      },
      "outputs": [

      ],
      "source": [
        "resampled_results = resampled_model.evaluate(test_features, test_labels,\n",
        "                                             batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_resampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYozM1IIITq"
      },
      "source": [
        "### Trace o ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fye_CiuYrZ1U"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
        "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Resampled\", train_labels, train_predictions_resampled,  color=colors[2])\n",
        "plot_roc(\"Test Resampled\", test_labels, test_predictions_resampled,  color=colors[2], linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3f0ywl8uqW"
      },
      "source": [
        "## Aplicando este tutorial ao seu problema\n",
        "\n",
        "A classificação de dados desequilibrada é uma tarefa inerentemente difícil, pois há tão poucos exemplos para aprender. Você deve sempre começar com os dados primeiro e fazer o seu melhor para coletar o máximo de amostras possível e dar uma ideia substancial sobre quais recursos podem ser relevantes para que o modelo possa obter o máximo de sua classe minoritária. Em algum ponto, seu modelo pode ter dificuldades para melhorar e produzir os resultados desejados, portanto, é importante ter em mente o contexto do seu problema e as compensações entre os diferentes tipos de erros."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "imbalanced_data.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
