{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUeKVCYTbcyT"
      },
      "source": [
        "#### Copyright 2019 Die TensorFlow-Autoren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4ellrPx7tdxq"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JfLUlawto_D"
      },
      "source": [
        "# Klassifizierung nach unausgeglichenen Daten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwdpaTKJOoPu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ansicht auf TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Führen Sie in Google Colab aus</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Quelle auf GitHub anzeigen</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Notizbuch herunterladen</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mthoSGBAOoX-"
      },
      "source": [
        "Dieses Tutorial zeigt, wie ein stark unausgeglichenes Dataset klassifiziert wird, bei dem die Anzahl der Beispiele in einer Klasse die Anzahl der Beispiele in einer anderen Klasse erheblich übertrifft. Sie arbeiten mit dem auf Kaggle gehosteten Datensatz zur [Erkennung](https://www.kaggle.com/mlg-ulb/creditcardfraud) von Kreditkartenbetrug. Ziel ist es, lediglich 492 betrügerische Transaktionen von insgesamt 284.807 Transaktionen aufzudecken. Sie verwenden [Keras](../../guide/keras/overview.ipynb) , um das Modell und die [Klassengewichte](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model) zu definieren, damit das Modell aus den unausgeglichenen Daten lernen kann. .\n",
        "\n",
        "Dieses Tutorial enthält vollständigen Code für:\n",
        "\n",
        "- Laden Sie eine CSV-Datei mit Pandas.\n",
        "- Erstellen Sie Zug-, Validierungs- und Testsätze.\n",
        "- Definieren und trainieren Sie ein Modell mit Keras (einschließlich des Festlegens von Klassengewichten).\n",
        "- Bewerten Sie das Modell anhand verschiedener Metriken (einschließlich Präzision und Rückruf).\n",
        "- Probieren Sie gängige Techniken für den Umgang mit unausgeglichenen Daten aus:\n",
        "    - Klassengewichtung\n",
        "    - Überabtastung\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRHmSyHxEIhN"
      },
      "source": [
        "## Konfiguration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM7hDSNClfoK"
      },
      "outputs": [

      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8o1FHzD-_y_"
      },
      "outputs": [

      ],
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3iZVjziKHmX"
      },
      "source": [
        "## Datenverarbeitung und Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sA9WOcmzH2D"
      },
      "source": [
        "### Laden Sie den Datensatz \"Kaggle Credit Card Fraud\" herunter\n",
        "\n",
        "Pandas ist eine Python-Bibliothek mit vielen hilfreichen Dienstprogrammen zum Laden und Arbeiten mit strukturierten Daten und kann zum Herunterladen von CSVs in einen Datenrahmen verwendet werden.\n",
        "\n",
        "Hinweis: Dieser Datensatz wurde im Rahmen einer Forschungskooperation von Worldline und der [Machine Learning Group](http://mlg.ulb.ac.be) der ULB (Université Libre de Bruxelles) zum Thema Big Data Mining und Betrugserkennung gesammelt und analysiert. Weitere Details zu aktuellen und früheren Projekten zu verwandten Themen finden Sie [hier](https://www.researchgate.net/project/Fraud-detection-5) und auf der Seite des [DefeatFraud-](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) Projekts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR_SnbMArXr7"
      },
      "outputs": [

      ],
      "source": [
        "file = tf.keras.utils\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fgdQgmwUFuj"
      },
      "outputs": [

      ],
      "source": [
        "raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKB_CVZFLpB"
      },
      "source": [
        "### Untersuchen Sie das Ungleichgewicht der Klassenbezeichnungen\n",
        "\n",
        "Schauen wir uns das Ungleichgewicht der Datensätze an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCJFrtuY2iLF"
      },
      "outputs": [

      ],
      "source": [
        "neg, pos = np.bincount(raw_df['Class'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnLKFQDsCBUg"
      },
      "source": [
        "Dies zeigt den kleinen Anteil positiver Proben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qox6ryyzwdr"
      },
      "source": [
        "### Bereinigen, teilen und normalisieren Sie die Daten\n",
        "\n",
        "Die Rohdaten haben einige Probleme. Erstens sind die Spalten `Time` und `Amount` zu variabel, um direkt verwendet zu werden. Löschen Sie die Spalte `Time` (da nicht klar ist, was dies bedeutet) und nehmen Sie das Protokoll der Spalte `Amount` , um den Bereich zu verringern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef42jTuxEjnj"
      },
      "outputs": [

      ],
      "source": [
        "cleaned_df = raw_df.copy()\n",
        "\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop('Time')\n",
        "\n",
        "# The `Amount` column covers a huge range. Convert to log-space.\n",
        "eps=0.001 # 0 => 0.1¢\n",
        "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSNgdQFFFQ6u"
      },
      "source": [
        "Teilen Sie den Datensatz in Zug-, Validierungs- und Testsätze auf. Der Validierungssatz wird während der Modellanpassung verwendet, um den Verlust und alle Metriken zu bewerten. Das Modell passt jedoch nicht zu diesen Daten. Der Testsatz wird während der Trainingsphase nicht verwendet und erst am Ende verwendet, um zu bewerten, wie gut sich das Modell auf neue Daten verallgemeinert. Dies ist besonders wichtig bei unausgeglichenen Datensätzen, bei denen eine [Überanpassung](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) aufgrund des Mangels an Trainingsdaten ein erhebliches Problem darstellt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfxhKg7Yr1-b"
      },
      "outputs": [

      ],
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "bool_train_labels = train_labels != 0\n",
        "val_labels = np.array(val_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a_Z_kBmr7Oh"
      },
      "source": [
        "Normalisieren Sie die Eingabefunktionen mit dem sklearn StandardScaler. Dadurch wird der Mittelwert auf 0 und die Standardabweichung auf 1 gesetzt.\n",
        "\n",
        "Hinweis: Der `StandardScaler` nur mit `train_features` , um sicherzustellen, dass das Modell nicht auf die Validierungs- oder Testsätze blickt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO-qEUmJ5JQg"
      },
      "outputs": [

      ],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "train_features = np.clip(train_features, -5, 5)\n",
        "val_features = np.clip(val_features, -5, 5)\n",
        "test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Validation labels shape:', val_labels.shape)\n",
        "print('Test labels shape:', test_labels.shape)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Validation features shape:', val_features.shape)\n",
        "print('Test features shape:', test_features.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF2nNfWKJ33w"
      },
      "source": [
        "Achtung: Wenn Sie ein Modell bereitstellen möchten, ist es wichtig, dass Sie die Vorverarbeitungsberechnungen beibehalten. Der einfachste Weg, sie als Ebenen zu implementieren und sie vor dem Export an Ihr Modell anzuhängen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ7m9nqDC3W6"
      },
      "source": [
        "### Schauen Sie sich die Datenverteilung an\n",
        "\n",
        "Vergleichen Sie als nächstes die Verteilungen der positiven und negativen Beispiele über einige Merkmale. Gute Fragen, die Sie sich an dieser Stelle stellen sollten, sind:\n",
        "\n",
        "- Sind diese Verteilungen sinnvoll?\n",
        "    - Ja. Sie haben die Eingabe normalisiert und diese konzentrieren sich hauptsächlich auf den Bereich `+/- 2` .\n",
        "- Können Sie den Unterschied zwischen den Verteilungen erkennen?\n",
        "    - Ja, die positiven Beispiele enthalten eine viel höhere Rate an Extremwerten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raK7hyjd_vf6"
      },
      "outputs": [

      ],
      "source": [
        "pos_df = pd.DataFrame(train_features[ bool_train_labels], columns = train_df.columns)\n",
        "neg_df = pd.DataFrame(train_features[~bool_train_labels], columns = train_df.columns)\n",
        "\n",
        "sns.jointplot(pos_df['V5'], pos_df['V6'],\n",
        "              kind='hex', xlim = (-5,5), ylim = (-5,5))\n",
        "plt.suptitle(\"Positive distribution\")\n",
        "\n",
        "sns.jointplot(neg_df['V5'], neg_df['V6'],\n",
        "              kind='hex', xlim = (-5,5), ylim = (-5,5))\n",
        "_ = plt.suptitle(\"Negative distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFK1u4JX16D8"
      },
      "source": [
        "## Definieren Sie das Modell und die Metriken\n",
        "\n",
        "Definieren Sie eine Funktion, die ein einfaches neuronales Netzwerk mit einer dicht verbundenen verborgenen Schicht, einer [Dropout-](https://developers.google.com/machine-learning/glossary/#dropout_regularization) Schicht zur Reduzierung von Überanpassungen und einer Ausgabe-Sigmoid-Schicht erstellt, die die Wahrscheinlichkeit einer betrügerischen Transaktion zurückgibt: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JQDzUqT3UYG"
      },
      "outputs": [

      ],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def make_model(metrics = METRICS, output_bias=None):\n",
        "  if output_bias is not None:\n",
        "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(\n",
        "          16, activation='relu',\n",
        "          input_shape=(train_features.shape[-1],)),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(1, activation='sigmoid',\n",
        "                         bias_initializer=output_bias),\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
        "      loss=keras.losses.BinaryCrossentropy(),\n",
        "      metrics=metrics)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU0GX6E6mieP"
      },
      "source": [
        "### Nützliche Metriken verstehen\n",
        "\n",
        "Beachten Sie, dass oben einige Metriken definiert sind, die vom Modell berechnet werden können und bei der Bewertung der Leistung hilfreich sind.\n",
        "\n",
        "- **Falsch** negative und **falsch** positive Ergebnisse sind Proben, die **falsch** klassifiziert wurden\n",
        "- **Echte** Negative und **echte** Positive sind Proben, die **korrekt** klassifiziert wurden\n",
        "- **Die Genauigkeit** ist der Prozentsatz der korrekt klassifizierten Beispiele\n",
        "\n",
        "> $ \\ frac {\\ text {true samples}} {\\ text {total samples}} $\n",
        "\n",
        "- **Präzision** ist der Prozentsatz der **vorhergesagten** Positiven, die korrekt klassifiziert wurden\n",
        "\n",
        "> $ \\ frac {\\ text {true positive}} {\\ text {true positive + false positive}} $\n",
        "\n",
        "- **Rückruf** ist der Prozentsatz der **tatsächlich** positiven Ergebnisse, die korrekt klassifiziert wurden\n",
        "\n",
        "> $ \\ frac {\\ text {wahre Positive}} {\\ text {wahre Positive + falsche Negative}} $\n",
        "\n",
        "- **AUC** bezieht sich auf die Fläche unter der Kurve einer Empfänger-Betriebskennlinie (ROC-AUC). Diese Metrik entspricht der Wahrscheinlichkeit, dass ein Klassifikator eine zufällige positive Stichprobe höher einstuft als eine zufällige negative Stichprobe.\n",
        "\n",
        "Hinweis: Die Genauigkeit ist keine hilfreiche Metrik für diese Aufgabe. Sie können bei dieser Aufgabe eine Genauigkeit von 99,8% + erreichen, indem Sie ständig Falsch vorhersagen.\n",
        "\n",
        "Weiterlesen:\n",
        "\n",
        "- [Richtig gegen Falsch und Positiv gegen Negativ](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)\n",
        "- [Richtigkeit](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
        "- [Präzision und Rückruf](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)\n",
        "- [ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYdhSAoaF_TK"
      },
      "source": [
        "## Basismodell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDbltVPg2m2q"
      },
      "source": [
        "### Erstellen Sie das Modell\n",
        "\n",
        "Erstellen und trainieren Sie nun Ihr Modell mit der zuvor definierten Funktion. Beachten Sie, dass das Modell mit einer Chargengröße von 2048 angepasst wird. Dies ist wichtig, um sicherzustellen, dass jede Charge eine gute Chance hat, einige positive Proben zu enthalten. Wenn die Stapelgröße zu klein wäre, hätten sie wahrscheinlich keine betrügerischen Transaktionen, aus denen sie lernen könnten.\n",
        "\n",
        "Hinweis: Dieses Modell wird das Klassenungleichgewicht nicht gut bewältigen. Sie werden es später in diesem Tutorial verbessern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouUkwPcGQsy3"
      },
      "outputs": [

      ],
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xlR_dekzw7C"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx7ND3_SqckO"
      },
      "source": [
        "Testen Sie das Modell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LopSd-yQqO3a"
      },
      "outputs": [

      ],
      "source": [
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKIgWqHms_03"
      },
      "source": [
        "### Optional: Stellen Sie die richtige Anfangsvorspannung ein."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk_3Ry6EoYDq"
      },
      "source": [
        "Diese anfänglichen Vermutungen sind nicht großartig. Sie wissen, dass der Datensatz nicht ausgeglichen ist. Stellen Sie die Vorspannung der Ausgabeebene so ein, dass sie dies widerspiegelt (siehe: [Ein Rezept für das Training neuronaler Netze: \"init well\"](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines) ). Dies kann bei der anfänglichen Konvergenz hilfreich sein."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdbfWDuVpo6k"
      },
      "source": [
        "Bei der Standard-Bias-Initialisierung sollte der Verlust bei `math.log(2) = 0.69314` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-oPqh3SoGXk"
      },
      "outputs": [

      ],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE-JRzfKqfhB"
      },
      "source": [
        "Die richtige Einstellung zum Einstellen kann abgeleitet werden aus:\n",
        "\n",
        "$$ p_0 = pos / (pos + neg) = 1 / (1 + e ^ {- b_0}) $$ $$ b_0 = -log_e (1 / p_0 - 1) $$ $$ b_0 = log_e (pos / neg ) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5KWPSjjstUS"
      },
      "outputs": [

      ],
      "source": [
        "initial_bias = np.log([pos/neg])\n",
        "initial_bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1juXI9yY1KD"
      },
      "source": [
        "Stellen Sie dies als anfängliche Verzerrung ein, und das Modell gibt viel vernünftigere anfängliche Vermutungen.\n",
        "\n",
        "Es sollte in der Nähe sein: `pos/total = 0.0018`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50oyu1uss0i-"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model(output_bias = initial_bias)\n",
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xqFYb2KqRHQ"
      },
      "source": [
        "Bei dieser Initialisierung sollte der anfängliche Verlust ungefähr:\n",
        "\n",
        "$$ - p_0log (p_0) - (1-p_0) log (1-p_0) = 0,01317 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVDqCWXDqHSc"
      },
      "outputs": [

      ],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDC8hvNr9yw"
      },
      "source": [
        "Dieser anfängliche Verlust ist ungefähr 50-mal geringer als bei einer naiven Initialisierung.\n",
        "\n",
        "Auf diese Weise muss das Modell nicht die ersten paar Epochen damit verbringen, zu lernen, dass positive Beispiele unwahrscheinlich sind. Dies erleichtert auch das Lesen von Plots des Verlusts während des Trainings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJj9ixKVBMT"
      },
      "source": [
        "### Überprüfen Sie die Anfangsgewichte\n",
        "\n",
        "Um die verschiedenen Trainingsläufe vergleichbarer zu machen, sollten Sie die Gewichte dieses Ausgangsmodells in einer Prüfpunktdatei aufbewahren und vor dem Training in jedes Modell laden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tSUm4yAVIif"
      },
      "outputs": [

      ],
      "source": [
        "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVXiLyqyZ8AX"
      },
      "source": [
        "### Vergewissern Sie sich, dass der Bias Fix hilft\n",
        "\n",
        "Vergewissern Sie sich vor dem Fortfahren schnell, dass die sorgfältige Bias-Initialisierung tatsächlich geholfen hat.\n",
        "\n",
        "Trainieren Sie das Modell für 20 Epochen mit und ohne diese sorgfältige Initialisierung und vergleichen Sie die Verluste: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm4-4K5RZ63Q"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "model.layers[-1].bias.assign([0.0])\n",
        "zero_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8DsLXHQaSql"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "careful_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3XsMBjhauFV"
      },
      "outputs": [

      ],
      "source": [
        "def plot_loss(history, label, n):\n",
        "  # Use a log scale to show the wide range of values.\n",
        "  plt.semilogy(history.epoch,  history.history['loss'],\n",
        "               color=colors[n], label='Train '+label)\n",
        "  plt.semilogy(history.epoch,  history.history['val_loss'],\n",
        "          color=colors[n], label='Val '+label,\n",
        "          linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  \n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxFaskm7beC7"
      },
      "outputs": [

      ],
      "source": [
        "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
        "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKMioV0ddG3R"
      },
      "source": [
        "Die obige Abbildung macht deutlich: In Bezug auf den Validierungsverlust bietet diese sorgfältige Initialisierung bei diesem Problem einen klaren Vorteil. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsA_7SEntRaV"
      },
      "source": [
        "### Trainiere das Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKAc8NCDnoR"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "baseline_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSaDBYU9xtP6"
      },
      "source": [
        "### Überprüfen Sie die Trainingshistorie\n",
        "\n",
        "In diesem Abschnitt erstellen Sie Diagramme der Genauigkeit und des Verlusts Ihres Modells im Trainings- und Validierungssatz. Diese sind nützlich, um nach Überanpassungen zu suchen. Weitere Informationen hierzu finden Sie in diesem [Lernprogramm](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit) .\n",
        "\n",
        "Darüber hinaus können Sie diese Diagramme für jede der oben erstellten Metriken erstellen. Als Beispiel sind falsche Negative enthalten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTSkhT1jyGu6"
      },
      "outputs": [

      ],
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6LReDsqlZlk"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(baseline_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCa4iWo6WDKR"
      },
      "source": [
        "Hinweis: Die Validierungskurve ist im Allgemeinen besser als die Trainingskurve. Dies wird hauptsächlich durch die Tatsache verursacht, dass die Dropout-Schicht bei der Bewertung des Modells nicht aktiv ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJC1booryouo"
      },
      "source": [
        "### Metriken auswerten\n",
        "\n",
        "Sie können eine [Verwirrungsmatrix verwenden,](https://developers.google.com/machine-learning/glossary/#confusion_matrix) um die tatsächlichen und vorhergesagten Beschriftungen zusammenzufassen, wobei die X-Achse die vorhergesagte Beschriftung und die Y-Achse die tatsächliche Beschriftung ist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNS796IJKrev"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVWBGfADwbWI"
      },
      "outputs": [

      ],
      "source": [
        "def plot_cm(labels, predictions, p=0.5):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "  plt.ylabel('Actual label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOTjD5Z5Wp1U"
      },
      "source": [
        "Bewerten Sie Ihr Modell im Testdatensatz und zeigen Sie die Ergebnisse für die oben erstellten Metriken an."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poh_hZngt2_9"
      },
      "outputs": [

      ],
      "source": [
        "baseline_results = model.evaluate(test_features, test_labels,\n",
        "                                  batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyZtSr1v6L4t"
      },
      "source": [
        "Wenn das Modell alles perfekt vorhergesagt hätte, wäre dies eine [Diagonalmatrix,](https://en.wikipedia.org/wiki/Diagonal_matrix) bei der Werte außerhalb der Hauptdiagonale, die auf falsche Vorhersagen hinweisen, Null wären. In diesem Fall zeigt die Matrix, dass Sie relativ wenige Fehlalarme haben, was bedeutet, dass es relativ wenige legitime Transaktionen gab, die falsch gekennzeichnet wurden. Trotz der Kosten für die Erhöhung der Anzahl falsch positiver Ergebnisse möchten Sie wahrscheinlich noch weniger falsche Negative haben. Dieser Kompromiss kann vorzuziehen sein, da durch falsche Negative betrügerische Transaktionen durchgeführt werden können, während durch falsche Positive eine E-Mail an einen Kunden gesendet werden kann, in der er aufgefordert wird, seine Kartenaktivität zu überprüfen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-QpQsip_F2Q"
      },
      "source": [
        "### Zeichnen Sie den ROC\n",
        "\n",
        "Zeichnen Sie nun den [ROC](https://developers.google.com/machine-learning/glossary#ROC) . Dieses Diagramm ist nützlich, da es auf einen Blick den Leistungsbereich zeigt, den das Modell durch einfaches Einstellen des Ausgabeschwellenwerts erreichen kann."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhaxsLSvANF9"
      },
      "outputs": [

      ],
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,20])\n",
        "  plt.ylim([80,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfHHspttKJE0"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdsFyp64DhY"
      },
      "source": [
        "Es sieht so aus, als ob die Genauigkeit relativ hoch ist, aber der Rückruf und die Fläche unter der ROC-Kurve (AUC) sind nicht so hoch, wie Sie vielleicht möchten. Klassifizierer stehen häufig vor Herausforderungen, wenn sie versuchen, sowohl die Präzision als auch den Rückruf zu maximieren. Dies gilt insbesondere für die Arbeit mit unausgeglichenen Datensätzen. Es ist wichtig, die Kosten für verschiedene Arten von Fehlern im Zusammenhang mit dem Problem zu berücksichtigen, das Sie interessiert. In diesem Beispiel kann ein falsches Negativ (eine betrügerische Transaktion wird übersehen) finanzielle Kosten verursachen, während ein falsches Positiv (eine Transaktion wird fälschlicherweise als betrügerisch gekennzeichnet) die Benutzerzufriedenheit verringern kann."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cveQoiMyGQCo"
      },
      "source": [
        "## Klassengewichte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePGp6GUE1WfH"
      },
      "source": [
        "### Klassengewichte berechnen\n",
        "\n",
        "Das Ziel besteht darin, betrügerische Transaktionen zu identifizieren, aber Sie haben nicht sehr viele dieser positiven Stichproben, mit denen Sie arbeiten können. Daher möchten Sie, dass der Klassifizierer die wenigen verfügbaren Beispiele stark gewichtet. Sie können dies tun, indem Sie Keras-Gewichte für jede Klasse über einen Parameter übergeben. Dies führt dazu, dass das Modell Beispielen aus einer unterrepräsentierten Klasse \"mehr Aufmerksamkeit\" schenkt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjGWErngGny7"
      },
      "outputs": [

      ],
      "source": [
        "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
        "# The sum of the weights of all examples stays the same.\n",
        "weight_for_0 = (1 / neg)*(total)/2.0 \n",
        "weight_for_1 = (1 / pos)*(total)/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk1OOE2ZSHzy"
      },
      "source": [
        "### Trainiere ein Modell mit Klassengewichten\n",
        "\n",
        "Versuchen Sie nun, das Modell mit Klassengewichten neu zu trainieren und zu bewerten, um festzustellen, wie sich dies auf die Vorhersagen auswirkt.\n",
        "\n",
        "Note: Using `class_weights` changes the range of the loss. This may affect the stability of the training depending on the optimizer. Optimizers whose step size is dependent on the magnitude of the gradient, like `optimizers.SGD`, may fail. The optimizer used here, `optimizers.Adam`, is unaffected by the scaling change. Also note that because of the weighting, the total losses are not comparable between the two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ589fn8ST3x"
      },
      "outputs": [

      ],
      "source": [
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0ynYRO0G3Lx"
      },
      "source": [
        "### Überprüfen Sie die Trainingshistorie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBe9FMO5ucTC"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(weighted_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy6WClTZIwQ"
      },
      "source": [
        "### Metriken auswerten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nifqscPGw-5w"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owKL2vdMBJr6"
      },
      "outputs": [

      ],
      "source": [
        "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
        "                                           batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_weighted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTh1rtDn8r4-"
      },
      "source": [
        "Hier können Sie sehen, dass bei Klassengewichten die Genauigkeit und Präzision geringer sind, weil es mehr falsch positive Ergebnisse gibt, aber umgekehrt sind der Rückruf und die AUC höher, weil das Modell auch mehr wahr positive Ergebnisse gefunden hat. Trotz geringerer Genauigkeit weist dieses Modell einen höheren Rückruf auf (und identifiziert betrügerischere Transaktionen). Natürlich sind beide Fehlertypen mit Kosten verbunden (Sie möchten Benutzer auch nicht nerven, indem Sie zu viele legitime Transaktionen als betrügerisch kennzeichnen). Berücksichtigen Sie sorgfältig die Kompromisse zwischen diesen verschiedenen Arten von Fehlern für Ihre Anwendung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXDAwyr0HYdX"
      },
      "source": [
        "### Zeichnen Sie den ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hzScIVZS1Xm"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
        "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
        "\n",
        "\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ysRtr6xHnXP"
      },
      "source": [
        "## Überabtastung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18VUHNc-UF5w"
      },
      "source": [
        "### Überprobe die Minderheitsklasse\n",
        "\n",
        "Ein verwandter Ansatz wäre das erneute Abtasten des Datensatzes durch Überabtasten der Minderheitsklasse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHirNp6u7OWp"
      },
      "outputs": [

      ],
      "source": [
        "pos_features = train_features[bool_train_labels]\n",
        "neg_features = train_features[~bool_train_labels]\n",
        "\n",
        "pos_labels = train_labels[bool_train_labels]\n",
        "neg_labels = train_labels[~bool_train_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBVbX7P7QrL"
      },
      "source": [
        "#### Verwenden von NumPy\n",
        "\n",
        "Sie können den Datensatz manuell ausgleichen, indem Sie aus den positiven Beispielen die richtige Anzahl von Zufallsindizes auswählen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUzGjSkwqT88"
      },
      "outputs": [

      ],
      "source": [
        "ids = np.arange(len(pos_features))\n",
        "choices = np.random.choice(ids, len(neg_features))\n",
        "\n",
        "res_pos_features = pos_features[choices]\n",
        "res_pos_labels = pos_labels[choices]\n",
        "\n",
        "res_pos_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ie_FFet6cep"
      },
      "outputs": [

      ],
      "source": [
        "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
        "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
        "\n",
        "order = np.arange(len(resampled_labels))\n",
        "np.random.shuffle(order)\n",
        "resampled_features = resampled_features[order]\n",
        "resampled_labels = resampled_labels[order]\n",
        "\n",
        "resampled_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYfJe2Kc-FAz"
      },
      "source": [
        "#### Verwenden von `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyixaST8v5P"
      },
      "source": [
        "If you're using `tf.data` the easiest way to produce balanced examples is to start with a `positive` and a `negative` dataset, and merge them. See [the tf.data guide](../../guide/data.ipynb) for more examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF4OZ-rI6xb6"
      },
      "outputs": [

      ],
      "source": [
        "BUFFER_SIZE = 100000\n",
        "\n",
        "def make_ds(features, labels):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
        "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
        "  return ds\n",
        "\n",
        "pos_ds = make_ds(pos_features, pos_labels)\n",
        "neg_ds = make_ds(neg_features, neg_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNQUx-OA-oJc"
      },
      "source": [
        "Jeder Datensatz enthält `(feature, label)` Paare:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llXc9rNH7Fbz"
      },
      "outputs": [

      ],
      "source": [
        "for features, label in pos_ds.take(1):\n",
        "  print(\"Features:\\n\", features.numpy())\n",
        "  print()\n",
        "  print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLEfjZO0-vbN"
      },
      "source": [
        "Führen Sie die beiden mithilfe von `experimental.sample_from_datasets` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7w9UQPT9wzE"
      },
      "outputs": [

      ],
      "source": [
        "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
        "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWXARdTdAuQK"
      },
      "outputs": [

      ],
      "source": [
        "for features, label in resampled_ds.take(1):\n",
        "  print(label.numpy().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irgqf3YxAyN0"
      },
      "source": [
        "Um diesen Datensatz verwenden zu können, benötigen Sie die Anzahl der Schritte pro Epoche.\n",
        "\n",
        "Die Definition von \"Epoche\" ist in diesem Fall weniger klar. Angenommen, es ist die Anzahl der Stapel, die erforderlich sind, um jedes negative Beispiel einmal zu sehen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH-7K46AAxpq"
      },
      "outputs": [

      ],
      "source": [
        "resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
        "resampled_steps_per_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ1BvEpcBVHP"
      },
      "source": [
        "### Trainieren Sie die überabgetasteten Daten\n",
        "\n",
        "Versuchen Sie nun, das Modell mit dem neu abgetasteten Datensatz zu trainieren, anstatt Klassengewichte zu verwenden, um zu sehen, wie diese Methoden verglichen werden.\n",
        "\n",
        "Hinweis: Da die Daten durch Replizieren der positiven Beispiele ausgeglichen wurden, ist die Gesamtgröße des Datensatzes größer und jede Epoche wird für weitere Trainingsschritte ausgeführt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soRQ89JYqd6b"
      },
      "outputs": [

      ],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=resampled_steps_per_epoch,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avALvzUp3T_c"
      },
      "source": [
        "Wenn der Trainingsprozess bei jeder Gradientenaktualisierung den gesamten Datensatz berücksichtigen würde, wäre diese Überabtastung im Wesentlichen identisch mit der Klassengewichtung.\n",
        "\n",
        "Wenn Sie das Modell jedoch chargenweise trainieren, wie Sie es hier getan haben, liefern die überabgetasteten Daten ein weicheres Gradientensignal: Anstatt jedes positive Beispiel in einer Charge mit großem Gewicht zu zeigen, werden sie jedes Mal in vielen verschiedenen Chargen mit einem angezeigt kleines Gewicht.\n",
        "\n",
        "Dieses weichere Gradientensignal erleichtert das Trainieren des Modells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHZ0HV76VC5"
      },
      "source": [
        "### Überprüfen Sie die Trainingshistorie\n",
        "\n",
        "Beachten Sie, dass die Verteilung der Metriken hier unterschiedlich ist, da die Trainingsdaten eine völlig andere Verteilung aufweisen als die Validierungs- und Testdaten. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoUGfr1vuivl"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(resampled_history )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PuH3A2vnwrh"
      },
      "source": [
        "### Umschulen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLxRL8eoDE5"
      },
      "source": [
        "Da das Training mit den ausgeglichenen Daten einfacher ist, kann das oben beschriebene Trainingsverfahren schnell überanpassen.\n",
        "\n",
        "So break up the epochs to give the `callbacks.EarlyStopping` finer control over when to stop training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_yn9I26qAHU"
      },
      "outputs": [

      ],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    # These are not real epochs\n",
        "    steps_per_epoch = 20,\n",
        "    epochs=10*EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuJYKv0gpBK1"
      },
      "source": [
        "### Überprüfen Sie die Trainingshistorie erneut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMycrpJwn39w"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(resampled_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUuE5HOWZiwP"
      },
      "source": [
        "### Metriken auswerten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0fmHSgXxFdW"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_resampled = resampled_model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_resampled = resampled_model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO0mMOYUDWFk"
      },
      "outputs": [

      ],
      "source": [
        "resampled_results = resampled_model.evaluate(test_features, test_labels,\n",
        "                                             batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_resampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYozM1IIITq"
      },
      "source": [
        "### Zeichnen Sie den ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fye_CiuYrZ1U"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
        "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Resampled\", train_labels, train_predictions_resampled,  color=colors[2])\n",
        "plot_roc(\"Test Resampled\", test_labels, test_predictions_resampled,  color=colors[2], linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3f0ywl8uqW"
      },
      "source": [
        "## Anwenden dieses Tutorials auf Ihr Problem\n",
        "\n",
        "Eine unausgewogene Datenklassifizierung ist von Natur aus eine schwierige Aufgabe, da es so wenige Beispiele gibt, aus denen man lernen kann. Sie sollten immer zuerst mit den Daten beginnen und Ihr Bestes tun, um so viele Stichproben wie möglich zu sammeln und gründlich darüber nachzudenken, welche Funktionen relevant sein können, damit das Modell Ihre Minderheitenklasse optimal nutzen kann. Irgendwann kann es sein, dass Ihr Modell Schwierigkeiten hat, die gewünschten Ergebnisse zu verbessern und zu erzielen. Daher ist es wichtig, den Kontext Ihres Problems und die Kompromisse zwischen verschiedenen Arten von Fehlern zu berücksichtigen."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "imbalanced_data.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
