{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUeKVCYTbcyT"
      },
      "source": [
        "#### Copyright 2019 Los autores de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4ellrPx7tdxq"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JfLUlawto_D"
      },
      "source": [
        "# Clasificación sobre datos desequilibrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwdpaTKJOoPu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar cuaderno</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mthoSGBAOoX-"
      },
      "source": [
        "Este tutorial demuestra cómo clasificar un conjunto de datos altamente desequilibrado en el que la cantidad de ejemplos en una clase supera en gran medida a los ejemplos en otra. Trabajará con el conjunto de datos de [detección de fraudes de tarjetas de crédito](https://www.kaggle.com/mlg-ulb/creditcardfraud) alojado en Kaggle. El objetivo es detectar solo 492 transacciones fraudulentas de 284.807 transacciones en total. Utilizará [Keras](../../guide/keras/overview.ipynb) para definir el modelo y [las ponderaciones de clase](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model) para ayudar al modelo a aprender de los datos desequilibrados. .\n",
        "\n",
        "Este tutorial contiene código completo para:\n",
        "\n",
        "- Cargue un archivo CSV usando Pandas.\n",
        "- Cree conjuntos de entrenamiento, validación y prueba.\n",
        "- Defina y entrene un modelo usando Keras (incluido el establecimiento de pesos de clase).\n",
        "- Evalúe el modelo utilizando varias métricas (incluida la precisión y la recuperación).\n",
        "- Pruebe técnicas comunes para lidiar con datos desequilibrados como:\n",
        "    - Ponderación de clase\n",
        "    - Sobremuestreo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRHmSyHxEIhN"
      },
      "source": [
        "## Preparar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM7hDSNClfoK"
      },
      "outputs": [

      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8o1FHzD-_y_"
      },
      "outputs": [

      ],
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3iZVjziKHmX"
      },
      "source": [
        "## Procesamiento y exploración de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sA9WOcmzH2D"
      },
      "source": [
        "### Descargue el conjunto de datos de fraude de tarjetas de crédito de Kaggle\n",
        "\n",
        "Pandas es una biblioteca de Python con muchas utilidades útiles para cargar y trabajar con datos estructurados y se puede usar para descargar archivos CSV en un marco de datos.\n",
        "\n",
        "Note: This dataset has been collected and analysed during a research collaboration of Worldline and the [Machine Learning Group](http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available [here](https://www.researchgate.net/project/Fraud-detection-5) and the page of the [DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR_SnbMArXr7"
      },
      "outputs": [

      ],
      "source": [
        "file = tf.keras.utils\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fgdQgmwUFuj"
      },
      "outputs": [

      ],
      "source": [
        "raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKB_CVZFLpB"
      },
      "source": [
        "### Examinar el desequilibrio de la etiqueta de clase\n",
        "\n",
        "Veamos el desequilibrio del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCJFrtuY2iLF"
      },
      "outputs": [

      ],
      "source": [
        "neg, pos = np.bincount(raw_df['Class'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnLKFQDsCBUg"
      },
      "source": [
        "Esto muestra la pequeña fracción de muestras positivas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qox6ryyzwdr"
      },
      "source": [
        "### Limpiar, dividir y normalizar los datos\n",
        "\n",
        "Los datos sin procesar tienen algunos problemas. Primero, las columnas `Time` y `Amount` son demasiado variables para usarlas directamente. Suelta la columna de `Time` (ya que no está claro qué significa) y toma el registro de la columna de `Amount` para reducir su rango."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef42jTuxEjnj"
      },
      "outputs": [

      ],
      "source": [
        "cleaned_df = raw_df.copy()\n",
        "\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop('Time')\n",
        "\n",
        "# The `Amount` column covers a huge range. Convert to log-space.\n",
        "eps=0.001 # 0 => 0.1¢\n",
        "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSNgdQFFFQ6u"
      },
      "source": [
        "Divida el conjunto de datos en conjuntos de entrenamiento, validación y prueba. El conjunto de validación se utiliza durante el ajuste del modelo para evaluar la pérdida y cualquier métrica; sin embargo, el modelo no se ajusta a estos datos. El conjunto de prueba no se usa por completo durante la fase de entrenamiento y solo se usa al final para evaluar qué tan bien se generaliza el modelo a nuevos datos. Esto es especialmente importante con conjuntos de datos desequilibrados donde el [sobreajuste](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) es una preocupación importante por la falta de datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfxhKg7Yr1-b"
      },
      "outputs": [

      ],
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "bool_train_labels = train_labels != 0\n",
        "val_labels = np.array(val_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a_Z_kBmr7Oh"
      },
      "source": [
        "Normalice las funciones de entrada con sklearn StandardScaler. Esto establecerá la media en 0 y la desviación estándar en 1.\n",
        "\n",
        "Nota: `StandardScaler` solo se ajusta mediante `train_features` para asegurarse de que el modelo no se vea en los conjuntos de validación o prueba. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO-qEUmJ5JQg"
      },
      "outputs": [

      ],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "train_features = np.clip(train_features, -5, 5)\n",
        "val_features = np.clip(val_features, -5, 5)\n",
        "test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Validation labels shape:', val_labels.shape)\n",
        "print('Test labels shape:', test_labels.shape)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Validation features shape:', val_features.shape)\n",
        "print('Test features shape:', test_features.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF2nNfWKJ33w"
      },
      "source": [
        "Precaución: si desea implementar un modelo, es fundamental que conserve los cálculos de preprocesamiento. La forma más sencilla de implementarlos como capas y adjuntarlos a su modelo antes de exportarlos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ7m9nqDC3W6"
      },
      "source": [
        "### Mira la distribución de datos\n",
        "\n",
        "A continuación, compare las distribuciones de los ejemplos positivos y negativos de algunas características. Buenas preguntas que debe hacerse en este punto son:\n",
        "\n",
        "- ¿Tienen sentido estas distribuciones?\n",
        "    - Si. Ha normalizado la entrada y estos se concentran principalmente en el rango `+/- 2` .\n",
        "- ¿Puedes ver la diferencia entre las distribuciones?\n",
        "    - Sí, los ejemplos positivos contienen una tasa mucho mayor de valores extremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raK7hyjd_vf6"
      },
      "outputs": [

      ],
      "source": [
        "pos_df = pd.DataFrame(train_features[ bool_train_labels], columns = train_df.columns)\n",
        "neg_df = pd.DataFrame(train_features[~bool_train_labels], columns = train_df.columns)\n",
        "\n",
        "sns.jointplot(pos_df['V5'], pos_df['V6'],\n",
        "              kind='hex', xlim = (-5,5), ylim = (-5,5))\n",
        "plt.suptitle(\"Positive distribution\")\n",
        "\n",
        "sns.jointplot(neg_df['V5'], neg_df['V6'],\n",
        "              kind='hex', xlim = (-5,5), ylim = (-5,5))\n",
        "_ = plt.suptitle(\"Negative distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFK1u4JX16D8"
      },
      "source": [
        "## Definir el modelo y las métricas\n",
        "\n",
        "Defina una función que cree una red neuronal simple con una capa oculta densamente conectada, una capa de [abandono](https://developers.google.com/machine-learning/glossary/#dropout_regularization) para reducir el sobreajuste y una capa sigmoidea de salida que devuelva la probabilidad de que una transacción sea fraudulenta: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JQDzUqT3UYG"
      },
      "outputs": [

      ],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def make_model(metrics = METRICS, output_bias=None):\n",
        "  if output_bias is not None:\n",
        "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(\n",
        "          16, activation='relu',\n",
        "          input_shape=(train_features.shape[-1],)),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(1, activation='sigmoid',\n",
        "                         bias_initializer=output_bias),\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
        "      loss=keras.losses.BinaryCrossentropy(),\n",
        "      metrics=metrics)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU0GX6E6mieP"
      },
      "source": [
        "### Comprender métricas útiles\n",
        "\n",
        "Tenga en cuenta que hay algunas métricas definidas anteriormente que pueden ser calculadas por el modelo que serán útiles al evaluar el desempeño.\n",
        "\n",
        "- **Los falsos** negativos y los **falsos** positivos son muestras que se clasificaron **incorrectamente**\n",
        "- **Los verdaderos** negativos y **verdaderos** positivos son muestras que se clasificaron **correctamente**\n",
        "- **La precisión** es el porcentaje de ejemplos clasificados correctamente\n",
        "\n",
        "> $ \\ frac {\\ text {muestras verdaderas}} {\\ text {muestras totales}} $\n",
        "\n",
        "- **La precisión** es el porcentaje de positivos **previstos** que se clasificaron correctamente\n",
        "\n",
        "> $ \\ frac {\\ text {verdaderos positivos}} {\\ text {verdaderos positivos + falsos positivos}} $\n",
        "\n",
        "- **El recuerdo** es el porcentaje de positivos **reales** que se clasificaron correctamente\n",
        "\n",
        "> $ \\ frac {\\ text {verdaderos positivos}} {\\ text {verdaderos positivos + falsos negativos}} $\n",
        "\n",
        "- **AUC se** refiere al área bajo la curva de una curva característica de funcionamiento del receptor (ROC-AUC). Esta métrica es igual a la probabilidad de que un clasificador clasifique una muestra aleatoria positiva más alta que una muestra aleatoria negativa.\n",
        "\n",
        "Nota: La precisión no es una métrica útil para esta tarea. Puede obtener una precisión superior al 99,8% en esta tarea si predice Falso todo el tiempo.\n",
        "\n",
        "Lee mas:\n",
        "\n",
        "- [Verdadero frente a falso y positivo frente a negativo](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)\n",
        "- [Exactitud](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
        "- [Precisión y recuperación](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)\n",
        "- [ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYdhSAoaF_TK"
      },
      "source": [
        "## Modelo de línea de base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDbltVPg2m2q"
      },
      "source": [
        "### Construye el modelo\n",
        "\n",
        "Ahora cree y entrene su modelo usando la función que se definió anteriormente. Tenga en cuenta que el modelo se ajusta con un tamaño de lote mayor que el predeterminado de 2048, esto es importante para garantizar que cada lote tenga una probabilidad decente de contener algunas muestras positivas. Si el tamaño del lote fuera demasiado pequeño, probablemente no tendrían transacciones fraudulentas de las que aprender.\n",
        "\n",
        "Nota: este modelo no manejará bien el desequilibrio de clases. Lo mejorará más adelante en este tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouUkwPcGQsy3"
      },
      "outputs": [

      ],
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xlR_dekzw7C"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx7ND3_SqckO"
      },
      "source": [
        "Prueba de ejecución del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LopSd-yQqO3a"
      },
      "outputs": [

      ],
      "source": [
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKIgWqHms_03"
      },
      "source": [
        "### Opcional: establezca el sesgo inicial correcto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk_3Ry6EoYDq"
      },
      "source": [
        "Estas suposiciones iniciales no son buenas. Sabes que el conjunto de datos está desequilibrado. Establezca el sesgo de la capa de salida para reflejar eso (Ver: [Una receta para entrenar redes neuronales: \"init well\"](http://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines) ). Esto puede ayudar con la convergencia inicial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdbfWDuVpo6k"
      },
      "source": [
        "Con la inicialización de sesgo predeterminada, la pérdida debe ser de aproximadamente `math.log(2) = 0.69314` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-oPqh3SoGXk"
      },
      "outputs": [

      ],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE-JRzfKqfhB"
      },
      "source": [
        "El sesgo correcto para establecer se puede derivar de:\n",
        "\n",
        "$$ p_0 = pos / (pos + neg) = 1 / (1 + e ^ {- b_0}) $$ $$ b_0 = -log_e (1 / p_0 - 1) $$ $$ b_0 = log_e (pos / neg ) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5KWPSjjstUS"
      },
      "outputs": [

      ],
      "source": [
        "initial_bias = np.log([pos/neg])\n",
        "initial_bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1juXI9yY1KD"
      },
      "source": [
        "Establezca eso como el sesgo inicial, y el modelo dará conjeturas iniciales mucho más razonables.\n",
        "\n",
        "Debe estar cerca de: `pos/total = 0.0018`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50oyu1uss0i-"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model(output_bias = initial_bias)\n",
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xqFYb2KqRHQ"
      },
      "source": [
        "Con esta inicialización, la pérdida inicial debería ser aproximadamente:\n",
        "\n",
        "$$ - p_0log (p_0) - (1-p_0) log (1-p_0) = 0.01317 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVDqCWXDqHSc"
      },
      "outputs": [

      ],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDC8hvNr9yw"
      },
      "source": [
        "Esta pérdida inicial es aproximadamente 50 veces menor que si hubiera sido con una inicialización ingenua.\n",
        "\n",
        "De esta manera, el modelo no necesita pasar las primeras épocas simplemente aprendiendo que los ejemplos positivos son poco probables. Esto también facilita la lectura de gráficos de la pérdida durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJj9ixKVBMT"
      },
      "source": [
        "### Punto de control de los pesos iniciales\n",
        "\n",
        "Para que las distintas ejecuciones de entrenamiento sean más comparables, mantenga los pesos de este modelo inicial en un archivo de punto de control y cárguelos en cada modelo antes del entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tSUm4yAVIif"
      },
      "outputs": [

      ],
      "source": [
        "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVXiLyqyZ8AX"
      },
      "source": [
        "### Confirme que la corrección de sesgo ayuda\n",
        "\n",
        "Antes de continuar, confirme rápidamente que la inicialización cuidadosa del sesgo realmente ayudó.\n",
        "\n",
        "Entrene el modelo durante 20 épocas, con y sin esta inicialización cuidadosa, y compare las pérdidas: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm4-4K5RZ63Q"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "model.layers[-1].bias.assign([0.0])\n",
        "zero_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8DsLXHQaSql"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "careful_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3XsMBjhauFV"
      },
      "outputs": [

      ],
      "source": [
        "def plot_loss(history, label, n):\n",
        "  # Use a log scale to show the wide range of values.\n",
        "  plt.semilogy(history.epoch,  history.history['loss'],\n",
        "               color=colors[n], label='Train '+label)\n",
        "  plt.semilogy(history.epoch,  history.history['val_loss'],\n",
        "          color=colors[n], label='Val '+label,\n",
        "          linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  \n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxFaskm7beC7"
      },
      "outputs": [

      ],
      "source": [
        "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
        "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKMioV0ddG3R"
      },
      "source": [
        "La figura anterior lo deja claro: en términos de pérdida de validación, en este problema, esta inicialización cuidadosa da una clara ventaja. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsA_7SEntRaV"
      },
      "source": [
        "### Entrena el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKAc8NCDnoR"
      },
      "outputs": [

      ],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "baseline_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSaDBYU9xtP6"
      },
      "source": [
        "### Consultar historial de entrenamiento\n",
        "\n",
        "En esta sección, producirá gráficos de la precisión y la pérdida de su modelo en el conjunto de entrenamiento y validación. Estos son útiles para verificar el sobreajuste, sobre el cual puede obtener más información en este [tutorial](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit) .\n",
        "\n",
        "Además, puede producir estos gráficos para cualquiera de las métricas que creó anteriormente. Los falsos negativos se incluyen como ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTSkhT1jyGu6"
      },
      "outputs": [

      ],
      "source": [
        "def plot_metrics(history):\n",
        "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6LReDsqlZlk"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(baseline_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCa4iWo6WDKR"
      },
      "source": [
        "Nota: Que la curva de validación generalmente funciona mejor que la curva de entrenamiento. Esto se debe principalmente al hecho de que la capa de abandono no está activa al evaluar el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJC1booryouo"
      },
      "source": [
        "### Evaluar métricas\n",
        "\n",
        "Puede utilizar una [matriz de confusión](https://developers.google.com/machine-learning/glossary/#confusion_matrix) para resumir las etiquetas reales frente a las predichas donde el eje X es la etiqueta predicha y el eje Y es la etiqueta real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNS796IJKrev"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVWBGfADwbWI"
      },
      "outputs": [

      ],
      "source": [
        "def plot_cm(labels, predictions, p=0.5):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "  plt.ylabel('Actual label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOTjD5Z5Wp1U"
      },
      "source": [
        "Evalúe su modelo en el conjunto de datos de prueba y muestre los resultados de las métricas que creó anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poh_hZngt2_9"
      },
      "outputs": [

      ],
      "source": [
        "baseline_results = model.evaluate(test_features, test_labels,\n",
        "                                  batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyZtSr1v6L4t"
      },
      "source": [
        "Si el modelo hubiera predicho todo perfectamente, esta sería una [matriz diagonal](https://en.wikipedia.org/wiki/Diagonal_matrix) donde los valores fuera de la diagonal principal, que indican predicciones incorrectas, serían cero. En este caso, la matriz muestra que tiene relativamente pocos falsos positivos, lo que significa que hubo relativamente pocas transacciones legítimas que se marcaron incorrectamente. Sin embargo, es probable que desee tener incluso menos falsos negativos a pesar del costo de aumentar el número de falsos positivos. Esta compensación puede ser preferible porque los falsos negativos permitirían que se realicen transacciones fraudulentas, mientras que los falsos positivos pueden hacer que se envíe un correo electrónico a un cliente para pedirle que verifique la actividad de su tarjeta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-QpQsip_F2Q"
      },
      "source": [
        "### Trazar la República de China\n",
        "\n",
        "Ahora traza la [República de China](https://developers.google.com/machine-learning/glossary#ROC) . Este gráfico es útil porque muestra, de un vistazo, el rango de rendimiento que el modelo puede alcanzar simplemente ajustando el umbral de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhaxsLSvANF9"
      },
      "outputs": [

      ],
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,20])\n",
        "  plt.ylim([80,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfHHspttKJE0"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdsFyp64DhY"
      },
      "source": [
        "Parece que la precisión es relativamente alta, pero la recuperación y el área bajo la curva ROC (AUC) no son tan altas como le gustaría. Los clasificadores a menudo enfrentan desafíos cuando intentan maximizar tanto la precisión como la recuperación, lo cual es especialmente cierto cuando se trabaja con conjuntos de datos desequilibrados. Es importante considerar los costos de los diferentes tipos de errores en el contexto del problema que le preocupa. En este ejemplo, un falso negativo (se pierde una transacción fraudulenta) puede tener un costo financiero, mientras que un falso positivo (una transacción se marca incorrectamente como fraudulenta) puede disminuir la felicidad del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cveQoiMyGQCo"
      },
      "source": [
        "## Pesos de clase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePGp6GUE1WfH"
      },
      "source": [
        "### Calcular pesos de clase\n",
        "\n",
        "El objetivo es identificar transacciones fraudulentas, pero no tiene muchas de esas muestras positivas con las que trabajar, por lo que le conviene que el clasificador tenga en cuenta los pocos ejemplos disponibles. Puede hacer esto pasando pesos de Keras para cada clase a través de un parámetro. Esto hará que el modelo \"preste más atención\" a ejemplos de una clase subrepresentada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjGWErngGny7"
      },
      "outputs": [

      ],
      "source": [
        "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
        "# The sum of the weights of all examples stays the same.\n",
        "weight_for_0 = (1 / neg)*(total)/2.0 \n",
        "weight_for_1 = (1 / pos)*(total)/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk1OOE2ZSHzy"
      },
      "source": [
        "### Entrena un modelo con pesos de clase\n",
        "\n",
        "Ahora intente volver a entrenar y evaluar el modelo con ponderaciones de clase para ver cómo afecta eso a las predicciones.\n",
        "\n",
        "Nota: El uso de `class_weights` cambia el rango de pérdida. Esto puede afectar la estabilidad del entrenamiento dependiendo del optimizador. Los optimizadores cuyo tamaño de paso depende de la magnitud del gradiente, como los `optimizers.SGD` , pueden fallar. El optimizador utilizado aquí, `optimizers.Adam` , no se ve afectado por el cambio de escala. También tenga en cuenta que debido a la ponderación, las pérdidas totales no son comparables entre los dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ589fn8ST3x"
      },
      "outputs": [

      ],
      "source": [
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0ynYRO0G3Lx"
      },
      "source": [
        "### Consultar historial de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBe9FMO5ucTC"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(weighted_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy6WClTZIwQ"
      },
      "source": [
        "### Evaluar métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nifqscPGw-5w"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owKL2vdMBJr6"
      },
      "outputs": [

      ],
      "source": [
        "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
        "                                           batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_weighted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTh1rtDn8r4-"
      },
      "source": [
        "Aquí puede ver que con las ponderaciones de clase, la exactitud y la precisión son menores porque hay más falsos positivos, pero a la inversa, la recuperación y el AUC son mayores porque el modelo también encontró más verdaderos positivos. A pesar de tener una menor precisión, este modelo tiene una mayor recuperación (e identifica más transacciones fraudulentas). Por supuesto, ambos tipos de error tienen un costo (tampoco querrá molestar a los usuarios marcando demasiadas transacciones legítimas como fraudulentas). Considere cuidadosamente las compensaciones entre estos diferentes tipos de errores para su aplicación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXDAwyr0HYdX"
      },
      "source": [
        "### Trazar la República de China"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hzScIVZS1Xm"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
        "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
        "\n",
        "\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ysRtr6xHnXP"
      },
      "source": [
        "## Sobremuestreo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18VUHNc-UF5w"
      },
      "source": [
        "### Sobremuestrear la clase minoritaria\n",
        "\n",
        "Un enfoque relacionado sería volver a muestrear el conjunto de datos sobremuestreando la clase minoritaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHirNp6u7OWp"
      },
      "outputs": [

      ],
      "source": [
        "pos_features = train_features[bool_train_labels]\n",
        "neg_features = train_features[~bool_train_labels]\n",
        "\n",
        "pos_labels = train_labels[bool_train_labels]\n",
        "neg_labels = train_labels[~bool_train_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBVbX7P7QrL"
      },
      "source": [
        "#### Usando NumPy\n",
        "\n",
        "Puede equilibrar el conjunto de datos manualmente eligiendo el número correcto de índices aleatorios de los ejemplos positivos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUzGjSkwqT88"
      },
      "outputs": [

      ],
      "source": [
        "ids = np.arange(len(pos_features))\n",
        "choices = np.random.choice(ids, len(neg_features))\n",
        "\n",
        "res_pos_features = pos_features[choices]\n",
        "res_pos_labels = pos_labels[choices]\n",
        "\n",
        "res_pos_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ie_FFet6cep"
      },
      "outputs": [

      ],
      "source": [
        "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
        "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
        "\n",
        "order = np.arange(len(resampled_labels))\n",
        "np.random.shuffle(order)\n",
        "resampled_features = resampled_features[order]\n",
        "resampled_labels = resampled_labels[order]\n",
        "\n",
        "resampled_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYfJe2Kc-FAz"
      },
      "source": [
        "#### Usando `tf.data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyixaST8v5P"
      },
      "source": [
        "Si está utilizando `tf.data` la forma más fácil de producir ejemplos equilibrados es comenzar con un conjunto de datos `positive` y `negative` y fusionarlos. Consulte [la guía tf.data](../../guide/data.ipynb) para obtener más ejemplos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF4OZ-rI6xb6"
      },
      "outputs": [

      ],
      "source": [
        "BUFFER_SIZE = 100000\n",
        "\n",
        "def make_ds(features, labels):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
        "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
        "  return ds\n",
        "\n",
        "pos_ds = make_ds(pos_features, pos_labels)\n",
        "neg_ds = make_ds(neg_features, neg_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNQUx-OA-oJc"
      },
      "source": [
        "Cada conjunto de datos proporciona pares `(feature, label)` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llXc9rNH7Fbz"
      },
      "outputs": [

      ],
      "source": [
        "for features, label in pos_ds.take(1):\n",
        "  print(\"Features:\\n\", features.numpy())\n",
        "  print()\n",
        "  print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLEfjZO0-vbN"
      },
      "source": [
        "Combina los dos juntos usando `experimental.sample_from_datasets` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7w9UQPT9wzE"
      },
      "outputs": [

      ],
      "source": [
        "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
        "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWXARdTdAuQK"
      },
      "outputs": [

      ],
      "source": [
        "for features, label in resampled_ds.take(1):\n",
        "  print(label.numpy().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irgqf3YxAyN0"
      },
      "source": [
        "Para usar este conjunto de datos, necesitará la cantidad de pasos por época.\n",
        "\n",
        "La definición de \"época\" en este caso es menos clara. Supongamos que es la cantidad de lotes necesarios para ver cada ejemplo negativo una vez:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH-7K46AAxpq"
      },
      "outputs": [

      ],
      "source": [
        "resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
        "resampled_steps_per_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ1BvEpcBVHP"
      },
      "source": [
        "### Entrene con los datos sobremuestreados\n",
        "\n",
        "Ahora intente entrenar el modelo con el conjunto de datos remuestreados en lugar de usar ponderaciones de clase para ver cómo se comparan estos métodos.\n",
        "\n",
        "Nota: Debido a que los datos se equilibraron replicando los ejemplos positivos, el tamaño total del conjunto de datos es mayor y cada época se ejecuta para más pasos de entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soRQ89JYqd6b"
      },
      "outputs": [

      ],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=resampled_steps_per_epoch,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avALvzUp3T_c"
      },
      "source": [
        "Si el proceso de entrenamiento considerara el conjunto de datos completo en cada actualización de gradiente, este sobremuestreo sería básicamente idéntico a la ponderación de la clase.\n",
        "\n",
        "Pero al entrenar el modelo por lotes, como lo hizo aquí, los datos sobremuestreados proporcionan una señal de gradiente más suave: en lugar de que cada ejemplo positivo se muestre en un lote con un gran peso, se muestran en muchos lotes diferentes cada vez con un pequeño peso.\n",
        "\n",
        "Esta señal de gradiente más suave facilita el entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHZ0HV76VC5"
      },
      "source": [
        "### Consultar historial de entrenamiento\n",
        "\n",
        "Tenga en cuenta que las distribuciones de métricas serán diferentes aquí, porque los datos de entrenamiento tienen una distribución totalmente diferente de los datos de validación y prueba. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoUGfr1vuivl"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(resampled_history )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PuH3A2vnwrh"
      },
      "source": [
        "### Reentrenar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLxRL8eoDE5"
      },
      "source": [
        "Debido a que el entrenamiento es más fácil con los datos balanceados, el procedimiento de entrenamiento anterior puede sobreajustarse rápidamente.\n",
        "\n",
        "So break up the epochs to give the `callbacks.EarlyStopping` finer control over when to stop training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_yn9I26qAHU"
      },
      "outputs": [

      ],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    # These are not real epochs\n",
        "    steps_per_epoch = 20,\n",
        "    epochs=10*EPOCHS,\n",
        "    callbacks = [early_stopping],\n",
        "    validation_data=(val_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuJYKv0gpBK1"
      },
      "source": [
        "### Vuelva a verificar el historial de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMycrpJwn39w"
      },
      "outputs": [

      ],
      "source": [
        "plot_metrics(resampled_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUuE5HOWZiwP"
      },
      "source": [
        "### Evaluar métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0fmHSgXxFdW"
      },
      "outputs": [

      ],
      "source": [
        "train_predictions_resampled = resampled_model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_resampled = resampled_model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO0mMOYUDWFk"
      },
      "outputs": [

      ],
      "source": [
        "resampled_results = resampled_model.evaluate(test_features, test_labels,\n",
        "                                             batch_size=BATCH_SIZE, verbose=0)\n",
        "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
        "  print(name, ': ', value)\n",
        "print()\n",
        "\n",
        "plot_cm(test_labels, test_predictions_resampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYozM1IIITq"
      },
      "source": [
        "### Trazar la República de China"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fye_CiuYrZ1U"
      },
      "outputs": [

      ],
      "source": [
        "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
        "plot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
        "plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n",
        "\n",
        "plot_roc(\"Train Resampled\", train_labels, train_predictions_resampled,  color=colors[2])\n",
        "plot_roc(\"Test Resampled\", test_labels, test_predictions_resampled,  color=colors[2], linestyle='--')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3f0ywl8uqW"
      },
      "source": [
        "## Aplicando este tutorial a su problema\n",
        "\n",
        "La clasificación de datos desequilibrada es una tarea intrínsecamente difícil, ya que hay muy pocas muestras de las que aprender. Siempre debe comenzar con los datos primero y hacer todo lo posible para recopilar tantas muestras como sea posible y pensar en profundidad sobre qué características pueden ser relevantes para que el modelo pueda aprovechar al máximo su clase minoritaria. En algún momento, su modelo puede tener dificultades para mejorar y producir los resultados que desea, por lo que es importante tener en cuenta el contexto de su problema y las compensaciones entre los diferentes tipos de errores."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "imbalanced_data.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
